{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new weather features (2nd version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find 10 closet stations, after removing outliers, calculate weighted mean for current station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data engineer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import queue\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "FILE_FOLDER = '../prediction_data/%s'\n",
    "AFTER_FILE_FOLDER = '../prediction_data/afterAnalysis/%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_dis_square(x1, y1, x2, y2):\n",
    "    dis = (x1 * 1.0 - x2) * (x1 * 1.0 - x2) + (y1 * 1.0 - y2) * (y1 * 1.0 - y2)\n",
    "    return math.sqrt(dis)\n",
    "\n",
    "def get_nearest_stations(df_grid_stations=pd.read_csv(AFTER_FILE_FOLDER % 'grid_stations.csv'),closest_num=10):\n",
    "    df_aq_stations = pd.read_csv(AFTER_FILE_FOLDER % 'aq_stations.csv')\n",
    "#     df_grid_stations = pd.read_csv(AFTER_FILE_FOLDER % 'grid_stations.csv')\n",
    "\n",
    "    aq_len = len(df_aq_stations.stationId)\n",
    "    grid_len = len(df_grid_stations)\n",
    "\n",
    "#     closest_num = 10\n",
    "    aq_closest_dict = {}\n",
    "\n",
    "    for i in range(aq_len):\n",
    "\n",
    "        aq_stationId = df_aq_stations.stationId[i]\n",
    "\n",
    "        aq_la = df_aq_stations.latitude[i]\n",
    "        aq_lo = df_aq_stations.longitude[i]\n",
    "        aq_closest_dict[aq_stationId] = []\n",
    "        aq_q = queue.PriorityQueue()\n",
    "\n",
    "        for j in range(grid_len):\n",
    "            grid_la = df_grid_stations.latitude[j]\n",
    "            grid_lo = df_grid_stations.longitude[j]\n",
    "            stationId = df_grid_stations.gridStationId[j]\n",
    "\n",
    "            y = (point_dis_square(aq_la, aq_lo, grid_la, grid_lo))\n",
    "            if (aq_q.qsize() < closest_num):\n",
    "                aq_q.put((-1.0 * y, stationId))\n",
    "            else:\n",
    "                if (aq_q.queue[0][0] < -1.0 * y):\n",
    "                    aq_q.get()\n",
    "                    aq_q.put((-1.0 * y, stationId))\n",
    "\n",
    "        while (not aq_q.empty()):\n",
    "            current_ele = aq_q.get()\n",
    "            aq_closest_dict[aq_stationId].append((-1*current_ele[0],current_ele[1]))\n",
    "        # pprint(aq_closest_dict[aq_stationId])\n",
    "\n",
    "    return aq_closest_dict,df_aq_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tupleArry_to_list(tupleArry, i_ele):\n",
    "    if(i_ele == 0):\n",
    "        w_list = list(map(lambda x:1.0 / x[i_ele],tupleArry))\n",
    "        return w_list\n",
    "    return list(map(lambda x:x[i_ele],tupleArry))\n",
    "\n",
    "def get_mean_without_outliers(df, feature_name):\n",
    "    df_sub = df.copy()\n",
    "    pre_mean = df_sub[feature_name].mean()\n",
    "    \"\"\"remove abs(num - mean) / mean > 50%\"\"\"\n",
    "    df_sub = df_sub[np.abs((df_sub[feature_name] - df_sub[feature_name].mean())/pre_mean) <= 0.5]\n",
    "    df_nearest_3 = df_sub.tail(3)\n",
    "    \n",
    "    weight_sum = df_nearest_3['weight'].sum()\n",
    "    df_nearest_3['weight'] = df_nearest_3['weight'] / weight_sum\n",
    "    df_nearest_3['after_weighted'] = df_nearest_3['weight'] * df_sub[feature_name]\n",
    "    return np.around(df_nearest_3['after_weighted'].sum(), decimals=2)\n",
    "\n",
    "\n",
    "def generate_features_for_aqStations(aq_closest_dict,df_grid, start_time, end_time):\n",
    "    starttime = datetime.datetime.now()\n",
    "    \n",
    "    df_grid_stations = df_grid.set_index(['station_id'])\n",
    "    dict_making = {\n",
    "        'aq_station_id':[],\n",
    "        'temperature':[],\n",
    "        'humidity':[],\n",
    "        'pressure':[],\n",
    "        'wind_speed':[],\n",
    "        'time':[]\n",
    "    }\n",
    "    \n",
    "    time_span = list(pd.date_range(start = start_time, end = end_time, closed=None, freq='H'))\n",
    "    time_span = list(map(lambda x:str(x),time_span))\n",
    "    \n",
    "    for aq_station_id,aq_station_value in tqdm(aq_closest_dict.items(),total=len(aq_closest_dict)):\n",
    "        stationId_list = tupleArry_to_list(aq_station_value, 1)\n",
    "        weight_dis = tupleArry_to_list(aq_station_value, 0)\n",
    "        \n",
    "        df_grid_temp = df_grid_stations.loc[stationId_list].reset_index().set_index(['time'])\n",
    "        for t_hour in time_span:\n",
    "#             print(df_grid_inOneHour)\n",
    "            try:\n",
    "                df_grid_inOneHour = df_grid_temp.loc[t_hour]\n",
    "            \n",
    "                df_merged = df_grid_inOneHour\n",
    "                df_merged.station_id = df_merged.station_id.astype(\"category\")\n",
    "                df_merged.station_id.cat.set_categories(stationId_list, inplace=True)\n",
    "                df_merged = df_merged.sort_values(['station_id']).reset_index()\n",
    "                df_merged['weight'] = pd.Series(weight_dis)\n",
    "                for f_name in ['temperature', 'pressure', 'humidity', 'wind_speed']:\n",
    "                    try:\n",
    "                        new_f = get_mean_without_outliers(df_merged[[f_name,'weight']],f_name)\n",
    "#                         new_f = df_merged[f_name].mean()\n",
    "                        dict_making[f_name].append(new_f)\n",
    "                    except:\n",
    "                        print(aq_station_id,'at',t_hour,'is NAN')\n",
    "                        dict_making[f_name].append(np.nan)\n",
    "            except:\n",
    "                print(aq_station_id,'at',t_hour,'is NAN')\n",
    "                for f_name in ['temperature', 'pressure', 'humidity', 'wind_speed']:\n",
    "                    dict_making[f_name].append(np.nan)\n",
    "                \n",
    "            dict_making['aq_station_id'].append(aq_station_id)\n",
    "            dict_making['time'].append(t_hour)\n",
    "#             break\n",
    "#         break\n",
    "            \n",
    "    endtime = datetime.datetime.now()\n",
    "\n",
    "    print('cost time:',(endtime - starttime).seconds)\n",
    "    new_df = pd.DataFrame.from_dict(dict_making)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station_id', 'time', 'weather', 'temperature', 'pressure', 'humidity',\n",
      "       'wind_speed', 'wind_direction', 'datetime'],\n",
      "      dtype='object')\n",
      "Index(['station_id', 'time', 'weather', 'temperature', 'pressure', 'humidity',\n",
      "       'wind_direction', 'wind_speed', 'datetime'],\n",
      "      dtype='object')\n",
      "Index(['station_id', 'temperature', 'pressure', 'humidity', 'wind_speed',\n",
      "       'time', 'datetime'],\n",
      "      dtype='object')\n",
      "Index(['station_id', 'temperature', 'pressure', 'humidity', 'wind_speed',\n",
      "       'time', 'datetime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['station_id', 'temperature', 'pressure','humidity', 'wind_speed', 'time', 'datetime']\n",
    "df_ow_stations_04 = pd.read_csv(FILE_FOLDER%'observedWeather_201804.csv')\n",
    "# print(df_ow_stations_04)\n",
    "df_ow_stations_04['datetime'] = pd.to_datetime(df_ow_stations_04['time'])\n",
    "# df_ow_stations_04\n",
    "df_grid_stations_04 = pd.read_csv(FILE_FOLDER%'gridWeather_201804.csv')\n",
    "df_grid_stations_04['datetime'] = pd.to_datetime(df_grid_stations_04['time'])\n",
    "\n",
    "df_ow_stations_04.columns = ['id', 'station_id', 'time', 'weather', 'temperature', 'pressure',\n",
    "       'humidity', 'wind_speed', 'wind_direction', 'datetime']\n",
    "df_ow_stations_04.drop('id',axis=1,inplace=True)\n",
    "print(df_ow_stations_04.columns)\n",
    "\n",
    "df_grid_stations_04.columns = ['id', 'station_id', 'time', 'weather', 'temperature', 'pressure',\n",
    "       'humidity', 'wind_direction', 'wind_speed', 'datetime']\n",
    "df_grid_stations_04.drop('id',axis=1,inplace=True)\n",
    "print(df_grid_stations_04.columns)\n",
    "\n",
    "df_ow_stations_04 = df_ow_stations_04[selected_features]\n",
    "print(df_ow_stations_04.columns)\n",
    "\n",
    "df_grid_stations_04 = df_grid_stations_04[selected_features]\n",
    "print(df_grid_stations_04.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = '2017-03-01 00:00:00'\n",
    "df_grid_stations_1701_1803 = pd.read_csv(FILE_FOLDER%'gridWeather_201701-201803.csv')\n",
    "df_ow_stations_1701_1801 = pd.read_csv(FILE_FOLDER%'observedWeather_201701-201801.csv')\n",
    "# start_date_18 = '2018-03-01 00:00:00'\n",
    "selected_features = ['station_id', 'temperature', 'pressure','humidity', 'wind_speed', 'time', 'datetime']\n",
    "df_grid_stations_1701_1803['datetime'] = pd.to_datetime(df_grid_stations_1701_1803['utc_time'])\n",
    "# df_grid_0103 = df_grid_stations_1701_1803[df_grid_stations_1701_1803['datetime'] >= start_date]\n",
    "# df_grid_0103.columns = ['station_id', 'longitude', 'latitude', 'time', 'temperature',\n",
    "#        'pressure', 'humidity', 'wind_direction', 'wind_speed', 'datetime']\n",
    "# print(df_grid_0103.columns)\n",
    "\n",
    "# df_grid_0103 = df_grid_0103[selected_features]\n",
    "# print(df_grid_0103.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-01-01 00:00:00'\n",
    "end_date = '2018-01-01 00:00:00'\n",
    "df_grid_2017_0212 = df_grid_stations_1701_1803[\n",
    "    (df_grid_stations_1701_1803['datetime'] >= start_date) &\n",
    "    (df_grid_stations_1701_1803['datetime'] < end_date) \n",
    "]\n",
    "df_grid_2017_0212.columns = ['station_id', 'longitude', 'latitude', 'time', 'temperature',\n",
    "       'pressure', 'humidity', 'wind_direction', 'wind_speed', 'datetime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508080"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid_2017_0212_neeeded  = df_grid_2017_0212[\n",
    "    df_grid_2017_0212['station_id'].isin(needed_grid_list)\n",
    "]\n",
    "len(df_grid_2017_0212_neeeded)\n",
    "# df_new_0103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [07:20<00:00, 12.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time: 440\n"
     ]
    }
   ],
   "source": [
    "# df_grid_0103\n",
    "df_new_2017 = generate_features_for_aqStations(aq_nearest_dict,df_grid_2017_0212_neeeded,\n",
    "                                          '2017-01-01 00:00:00','2017-12-31 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aq_station_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>-5.943333</td>\n",
       "      <td>70.966667</td>\n",
       "      <td>1021.273333</td>\n",
       "      <td>4.553333</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>-3.466667</td>\n",
       "      <td>60.483333</td>\n",
       "      <td>1021.153333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>-0.993333</td>\n",
       "      <td>50.006667</td>\n",
       "      <td>1021.036667</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>1.483333</td>\n",
       "      <td>39.526667</td>\n",
       "      <td>1020.913333</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>36.936667</td>\n",
       "      <td>1020.220000</td>\n",
       "      <td>3.996667</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aq_station_id  temperature   humidity     pressure  wind_speed  \\\n",
       "0     dongsi_aq    -5.943333  70.966667  1021.273333    4.553333   \n",
       "1     dongsi_aq    -3.466667  60.483333  1021.153333    4.066667   \n",
       "2     dongsi_aq    -0.993333  50.006667  1021.036667    3.670000   \n",
       "3     dongsi_aq     1.483333  39.526667  1020.913333    3.390000   \n",
       "4     dongsi_aq     2.640000  36.936667  1020.220000    3.996667   \n",
       "\n",
       "                  time  \n",
       "0  2017-01-01 00:00:00  \n",
       "1  2017-01-01 01:00:00  \n",
       "2  2017-01-01 02:00:00  \n",
       "3  2017-01-01 03:00:00  \n",
       "4  2017-01-01 04:00:00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aq_stations = pd.read_csv(AFTER_FILE_FOLDER % 'grid_stations.csv')\n",
    "aq_nearest_dict, df_aq_stations = get_nearest_stations(df_aq_stations,10)\n",
    "aq_nearest_dict\n",
    "# grid_set = set()\n",
    "grid_n_list = []\n",
    "for k,v in aq_nearest_dict.items():\n",
    "    cc = list(map(lambda x:x[1],v))\n",
    "    grid_n_list += cc\n",
    "needed_grid_list = list(set(grid_n_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(needed_grid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grid_weather = pd.read_csv(FILE_FOLDER % 'gridWeather_20180501-20180502.csv')\n",
    "test_grid_weather = test_grid_weather[['station_id', 'time', 'temperature', 'pressure','humidity', 'wind_speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]/Users/haomao/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/Users/haomao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/haomao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "100%|██████████| 35/35 [08:01<00:00, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time: 481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_grid_test_neeeded = test_grid_weather[test_grid_weather['station_id'].isin(needed_grid_list)]\n",
    "# df_grid_test_neeeded \n",
    "df_test = generate_features_for_aqStations(aq_nearest_dict,df_grid_test_neeeded,\n",
    "                                          '2018-05-01 00:00:00','2018-05-02 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(AFTER_FILE_FOLDER % 'test_weather.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
