{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "FILE_FOLDER = '../prediction_data/%s'\n",
    "AFTER_FILE_FOLDER = '../prediction_data/afterAnalysis/%s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stationId', 'utc_time', 'PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2'], dtype='object')\n",
      "total records: 311010\n",
      "NAN of O3: 83263\n",
      "Index(['stationId', 'utc_time', 'PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2'], dtype='object')\n",
      "total records: 49420\n",
      "NAN of O3: 12912\n",
      "Index(['id', 'station_id', 'time', 'PM25_Concentration', 'PM10_Concentration',\n",
      "       'NO2_Concentration', 'CO_Concentration', 'O3_Concentration',\n",
      "       'SO2_Concentration'],\n",
      "      dtype='object')\n",
      "total records: 23310\n",
      "NAN of O3: 4885\n"
     ]
    }
   ],
   "source": [
    "aq_17_18 = pd.read_csv(FILE_FOLDER % 'airQuality_201701-201801.csv')\n",
    "print(aq_17_18.columns)\n",
    "print('total records:',len(aq_17_18))\n",
    "print('NAN of O3:',len(aq_17_18.loc[aq_17_18['PM10'].isnull()]))\n",
    "\n",
    "\n",
    "aq18_02_03 = pd.read_csv(FILE_FOLDER % 'airQuality_201802-201803.csv')\n",
    "print(aq18_02_03.columns)\n",
    "print('total records:',len(aq18_02_03))\n",
    "print('NAN of O3:',len(aq18_02_03.loc[aq18_02_03['PM10'].isnull()]))\n",
    "\n",
    "\n",
    "aq18_04 = pd.read_csv(FILE_FOLDER % 'aiqQuality_201804.csv')\n",
    "print(aq18_04.columns)\n",
    "print('total records:',len(aq18_04))\n",
    "print('NAN of O3:',len(aq18_04.loc[aq18_04['PM10_Concentration'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>2018-04-01 02:00:00</td>\n",
       "      <td>259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiantan_aq</td>\n",
       "      <td>2018-04-01 02:00:00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>2018-04-01 02:00:00</td>\n",
       "      <td>240.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wanshouxigong_aq</td>\n",
       "      <td>2018-04-01 02:00:00</td>\n",
       "      <td>255.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aotizhongxin_aq</td>\n",
       "      <td>2018-04-01 02:00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id                 time   PM25   PM10    O3\n",
       "0         dongsi_aq  2018-04-01 02:00:00  259.0    NaN  56.0\n",
       "1        tiantan_aq  2018-04-01 02:00:00  250.0    NaN  64.0\n",
       "2       guanyuan_aq  2018-04-01 02:00:00  240.0  246.0  49.0\n",
       "3  wanshouxigong_aq  2018-04-01 02:00:00  255.0  260.0  65.0\n",
       "4   aotizhongxin_aq  2018-04-01 02:00:00  266.0    NaN  45.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_features = ['station_id', 'time', 'PM25', 'PM10', 'O3']\n",
    "aq_17_18 = aq_17_18.rename(index=str, columns={\"stationId\": \"station_id\",\"utc_time\": \"time\", \"PM2.5\": \"PM25\"})\n",
    "aq18_02_03 = aq18_02_03.rename(index=str, columns={\"stationId\": \"station_id\",\"utc_time\": \"time\", \"PM2.5\": \"PM25\"})\n",
    "aq18_04 = aq18_04.rename(index=str, columns={\"PM25_Concentration\": \"PM25\",\n",
    "                                             \"PM10_Concentration\":\"PM10\",\n",
    "                                             \"O3_Concentration\":\"O3\"})\n",
    "aq_17_18 = aq_17_18[need_features]\n",
    "aq18_02_03 = aq18_02_03[need_features]\n",
    "aq18_04 = aq18_04[need_features]\n",
    "aq18_04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98490"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq = aq_17_18.append(aq18_02_03)\n",
    "# df_aq = aq18_02_03\n",
    "df_aq = df_aq.append(aq18_04)\n",
    "df_aq = df_aq.reset_index()\n",
    "df_aq['datetime'] = pd.to_datetime(df_aq['time'])\n",
    "df_aq_0104 = df_aq[df_aq['datetime'] >= '2018-01-01 00:00:00']\n",
    "df_aq_0104 = df_aq_0104[need_features]\n",
    "\n",
    "len(df_aq_0104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq_station_name = ['dongsi_aq', 'tiantan_aq', 'guanyuan_aq', 'wanshouxigong_aq',\n",
    "                   'aotizhongxin_aq', 'nongzhanguan_aq', 'wanliu_aq', 'beibuxinqu_aq', \n",
    "                   'zhiwuyuan_aq', 'fengtaihuayuan_aq', 'yungang_aq', 'gucheng_aq', \n",
    "                   'fangshan_aq', 'daxing_aq', 'yizhuang_aq', 'tongzhou_aq',\n",
    "                   'shunyi_aq', 'pingchang_aq', 'mentougou_aq', 'pinggu_aq', \n",
    "                   'huairou_aq', 'miyun_aq', 'yanqin_aq', 'dingling_aq', 'badaling_aq', \n",
    "                   'miyunshuiku_aq', 'donggaocun_aq', 'yongledian_aq', 'yufa_aq', \n",
    "                   'liulihe_aq', 'qianmen_aq', 'yongdingmennei_aq', 'xizhimenbei_aq',\n",
    "                   'nansanhuan_aq', 'dongsihuan_aq']\n",
    "len(aq_station_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the Time Series (Time) Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_aq_data(original_df,start_time,end_time):\n",
    "    pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "    df_aq_copy = original_df.copy()\n",
    "    df_aq_copy.set_index(['station_id','time'], inplace=True)\n",
    "    \n",
    "    making_dict = {\n",
    "        'station_id':[],\n",
    "        'time':[],\n",
    "        'PM25':[],\n",
    "        \"PM10\":[],\n",
    "        \"O3\":[]\n",
    "    }\n",
    "    time_span = list(pd.date_range(start = start_time, end = end_time, closed=None, freq='H'))\n",
    "    time_span = list(map(lambda x:str(x),time_span))\n",
    "    for c_time in tqdm(time_span,total = len(time_span)):\n",
    "        for c_station in aq_station_name:\n",
    "            making_dict['station_id'].append(c_station)\n",
    "            making_dict['time'].append(c_time)\n",
    "            try:\n",
    "                ele = df_aq_copy.loc[(c_station,c_time)]\n",
    "                for p in pp:\n",
    "                    making_dict[p].append(ele[p].mean())\n",
    "            except:\n",
    "                for p in pp:\n",
    "                    making_dict[p].append(np.nan)\n",
    "    new_df = pd.DataFrame.from_dict(making_dict)\n",
    "    return new_df\n",
    "    \n",
    "# newwww_df =  arrange_aq_data(df_aq_0104,'2018-01-01 00:00:00','2018-04-30 23:00:00')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10920 [00:00<?, ?it/s]/Users/haomao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "100%|██████████| 10920/10920 [13:06<00:00, 13.89it/s]\n"
     ]
    }
   ],
   "source": [
    "df_aq_17 = pd.read_csv(FILE_FOLDER % 'airQuality_201701-201801.csv')\n",
    "df_aq_18_0203 = pd.read_csv(FILE_FOLDER % 'airQuality_201802-201803.csv')\n",
    "df_aq_17_1803 = df_aq_17.append(df_aq_18_0203)\n",
    "df_aq_17_1803 = df_aq_17_1803[['stationId', 'utc_time', 'PM2.5', 'PM10','O3']]\n",
    "\n",
    "df_aq_17_1803.rename(index=str, columns={'stationId':'station_id','utc_time':'time','PM2.5':'PM25'},inplace = True)\n",
    "\n",
    "arranged_aq_17_1803 =  arrange_aq_data(df_aq_17_1803,'2017-01-01 00:00:00','2018-03-31 23:00:00')\n",
    "# len(list(pd.date_range(start = '2018-01-01 00:00:00', end = '2018-04-30 23:00:00', closed=None, freq='H')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling One Station by others' mean in the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_data(original_df):\n",
    "    pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "    df_aq_copy = original_df.copy()\n",
    "    df_aq_copy.set_index(['station_id','time'], inplace=True)\n",
    "    # pp = [\"PM25\"]\n",
    "    for p in pp:\n",
    "        df_NOT_NAN = original_df.loc[original_df[p].isnull() == False]\n",
    "        df_NAN = original_df.loc[original_df[p].isnull()]\n",
    "    #     print(len(df_NAN),len(df_NOT_NAN))\n",
    "        df_NAN.set_index(['station_id','time'], inplace=True)\n",
    "        miss_aq_name = set()\n",
    "        for i in df_NAN.index.values.tolist():\n",
    "            miss_aq_name.add(i[0])\n",
    "        miss_aq_name = list(miss_aq_name)\n",
    "\n",
    "        for aq_name in tqdm(miss_aq_name,total = len(miss_aq_name)):\n",
    "            for time in df_NAN.loc[aq_name].index.values.tolist():\n",
    "                mean_value = df_NOT_NAN[df_NOT_NAN['time'] == time][p].mean()\n",
    "                df_aq_copy.at[(aq_name,time),p] = mean_value\n",
    "                \n",
    "    return df_aq_copy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [21:58<00:00, 36.52s/it]\n",
      "100%|██████████| 35/35 [40:33<00:00, 62.07s/it]\n",
      "100%|██████████| 35/35 [20:43<00:00, 32.73s/it]\n"
     ]
    }
   ],
   "source": [
    "new_aq_17_1803 = fill_missing_data(arranged_aq_17_1803)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing num of PM25:  51079\n",
      "Missing num of PM10:  123025\n",
      "Missing num of O3:  51390\n",
      "after filling\n",
      "Missing num of PM25:  28630\n",
      "Missing num of PM10:  31675\n",
      "Missing num of O3:  28630\n"
     ]
    }
   ],
   "source": [
    "pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "for p in pp:\n",
    "    m_n = len(arranged_aq_17_1803.loc[arranged_aq_17_1803[p].isnull()])\n",
    "    print('Missing num of %s: '%p, m_n)\n",
    "print('after filling')\n",
    "pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "for p in pp:\n",
    "    m_n = len(new_aq_17_1803.loc[new_aq_17_1803[p].isnull()])\n",
    "    print('Missing num of %s: '%p, m_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>nongzhanguan_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>wanliu_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>beibuxinqu_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>373.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>327.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>gucheng_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>fangshan_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>314.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>yizhuang_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>246.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>tongzhou_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>shunyi_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>pingchang_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>mentougou_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>pinggu_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>huairou_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>miyun_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>yanqin_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>badaling_aq</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station_id                 time   PM25   PM10    O3\n",
       "880    nongzhanguan_aq  2017-01-02 01:00:00   13.0    NaN  19.0\n",
       "881          wanliu_aq  2017-01-02 01:00:00   28.0    NaN  11.0\n",
       "882      beibuxinqu_aq  2017-01-02 01:00:00  140.0    NaN   5.0\n",
       "883       zhiwuyuan_aq  2017-01-02 01:00:00   17.0    NaN  53.0\n",
       "884  fengtaihuayuan_aq  2017-01-02 01:00:00  373.0  399.0   9.0\n",
       "885         yungang_aq  2017-01-02 01:00:00  327.0    NaN   6.0\n",
       "886         gucheng_aq  2017-01-02 01:00:00   28.0    NaN  14.0\n",
       "887        fangshan_aq  2017-01-02 01:00:00  289.0    NaN   6.0\n",
       "888          daxing_aq  2017-01-02 01:00:00  314.0  343.0   7.0\n",
       "889        yizhuang_aq  2017-01-02 01:00:00  246.0  261.0   8.0\n",
       "890        tongzhou_aq  2017-01-02 01:00:00   31.0    NaN  23.0\n",
       "891          shunyi_aq  2017-01-02 01:00:00  107.0    NaN   9.0\n",
       "892       pingchang_aq  2017-01-02 01:00:00   18.0    NaN  36.0\n",
       "893       mentougou_aq  2017-01-02 01:00:00   28.0    NaN  29.0\n",
       "894          pinggu_aq  2017-01-02 01:00:00  358.0    NaN   5.0\n",
       "895         huairou_aq  2017-01-02 01:00:00  101.0    NaN   2.0\n",
       "896           miyun_aq  2017-01-02 01:00:00   83.0    NaN   7.0\n",
       "897          yanqin_aq  2017-01-02 01:00:00   35.0   52.0  19.0\n",
       "898        dingling_aq  2017-01-02 01:00:00   10.0    NaN  69.0\n",
       "899        badaling_aq  2017-01-02 01:00:00   17.0   18.0  58.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arranged_aq_17_1803[880:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_for_another(df_after,df_target):\n",
    "    pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "    df_aq_copy = df_target.copy()\n",
    "    df_aq_copy.set_index(['station_id','time'], inplace=True)\n",
    "    df_after_copy = df_after.set_index(['station_id','time'], inplace=True)\n",
    "    # pp = [\"PM25\"]\n",
    "    for p in pp:\n",
    "        df_NAN = df_target.loc[df_target[p].isnull()]\n",
    "    #     print(len(df_NAN),len(df_NOT_NAN))\n",
    "        df_NAN.set_index(['station_id','time'], inplace=True)\n",
    "        miss_aq_name = set()\n",
    "        for i in df_NAN.index.values.tolist():\n",
    "            miss_aq_name.add(i[0])\n",
    "        miss_aq_name = list(miss_aq_name)\n",
    "\n",
    "        for aq_name in tqdm(miss_aq_name,total = len(miss_aq_name)):\n",
    "            for time in df_NAN.loc[aq_name].index.values.tolist():\n",
    "                mean_value = df_after_copy.loc[aq_name].loc[time][p]\n",
    "                df_aq_copy.set_value((aq_name,time),p,mean_value)\n",
    "    return df_aq_copy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_04 = pd.read_csv(AFTER_FILE_FOLDER % 'aq18_02_04.csv')\n",
    "df_after_ = pd.read_csv(AFTER_FILE_FOLDER % 'aq17_03_07.csv')\n",
    "df_after_ = new_d.append(df_after_04,sort=False)\n",
    "\n",
    "df_train = pd.read_csv(AFTER_FILE_FOLDER % 'train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing num of PM25:  10483\n",
      "Missing num of PM10:  38709\n",
      "Missing num of O3:  9713\n"
     ]
    }
   ],
   "source": [
    "pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "for p in pp:\n",
    "    m_n = len(df_train.loc[df_train[p].isnull()])\n",
    "    print('Missing num of %s: '%p, m_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_for_another(df_after,df_target):\n",
    "    pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "    df_aq_copy = df_target.copy()\n",
    "    df_aq_copy.set_index(['station_id','time'], inplace=True)\n",
    "    df_after_copy = df_after.set_index(['station_id','time'])\n",
    "    # pp = [\"PM25\"]\n",
    "    for p in pp:\n",
    "        df_NAN = df_target.loc[df_target[p].isnull()]\n",
    "    #     print(len(df_NAN),len(df_NOT_NAN))\n",
    "        df_NAN.set_index(['station_id','time'], inplace=True)\n",
    "        miss_aq_name = set()\n",
    "        for i in df_NAN.index.values.tolist():\n",
    "            miss_aq_name.add(i[0])\n",
    "        miss_aq_name = list(miss_aq_name)\n",
    "\n",
    "        for aq_name in tqdm(miss_aq_name,total = len(miss_aq_name)):\n",
    "            for time in df_NAN.loc[aq_name].index.values.tolist():\n",
    "                mean_value = df_after_copy.loc[aq_name].loc[time][p].mean()\n",
    "#                 pprint(mean_value)\n",
    "                df_aq_copy.set_value((aq_name,time),p,mean_value)\n",
    "\n",
    "    return df_aq_copy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train_d = fill_missing_for_another(df_after_,df_train)\n",
    "df_train = df_train.rename(index=str, columns={\"aq_station_id\": \"station_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A/Users/haomao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "  3%|▎         | 1/35 [00:01<00:42,  1.25s/it]\u001b[A\n",
      "  6%|▌         | 2/35 [00:01<00:30,  1.09it/s]\u001b[A\n",
      "  9%|▊         | 3/35 [00:01<00:23,  1.35it/s]\u001b[A\n",
      " 11%|█▏        | 4/35 [00:02<00:19,  1.62it/s]\u001b[A\n",
      " 14%|█▍        | 5/35 [00:02<00:16,  1.87it/s]\u001b[A\n",
      " 17%|█▋        | 6/35 [00:02<00:13,  2.19it/s]\u001b[A\n",
      " 20%|██        | 7/35 [00:02<00:11,  2.52it/s]\u001b[A\n",
      " 23%|██▎       | 8/35 [00:03<00:09,  2.75it/s]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:03<00:08,  3.22it/s]\u001b[A\n",
      " 29%|██▊       | 10/35 [00:03<00:06,  3.63it/s]\u001b[A\n",
      " 31%|███▏      | 11/35 [00:03<00:05,  4.24it/s]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:03<00:05,  4.57it/s]\u001b[A\n",
      " 37%|███▋      | 13/35 [00:04<00:04,  4.65it/s]\u001b[A\n",
      " 40%|████      | 14/35 [00:04<00:06,  3.11it/s]\u001b[A\n",
      " 43%|████▎     | 15/35 [00:07<00:19,  1.00it/s]\u001b[A\n",
      " 46%|████▌     | 16/35 [00:08<00:18,  1.05it/s]\u001b[A\n",
      " 49%|████▊     | 17/35 [00:10<00:24,  1.38s/it]\u001b[A\n",
      " 51%|█████▏    | 18/35 [00:10<00:17,  1.02s/it]\u001b[A\n",
      " 54%|█████▍    | 19/35 [00:10<00:12,  1.26it/s]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:11<00:09,  1.52it/s]\u001b[A\n",
      " 60%|██████    | 21/35 [00:11<00:07,  1.79it/s]\u001b[A\n",
      " 63%|██████▎   | 22/35 [00:12<00:06,  1.89it/s]\u001b[A\n",
      " 66%|██████▌   | 23/35 [00:12<00:06,  1.84it/s]\u001b[A\n",
      " 69%|██████▊   | 24/35 [00:13<00:05,  1.96it/s]\u001b[A\n",
      " 71%|███████▏  | 25/35 [00:13<00:04,  2.38it/s]\u001b[A\n",
      " 74%|███████▍  | 26/35 [00:13<00:03,  2.54it/s]\u001b[A\n",
      " 77%|███████▋  | 27/35 [00:13<00:02,  2.99it/s]\u001b[A\n",
      " 80%|████████  | 28/35 [00:14<00:02,  2.86it/s]\u001b[A\n",
      " 83%|████████▎ | 29/35 [00:15<00:03,  1.94it/s]\u001b[A\n",
      " 86%|████████▌ | 30/35 [00:15<00:02,  2.17it/s]\u001b[A\n",
      " 91%|█████████▏| 32/35 [00:18<00:02,  1.36it/s]\u001b[A\n",
      " 94%|█████████▍| 33/35 [00:18<00:01,  1.75it/s]\u001b[A\n",
      " 97%|█████████▋| 34/35 [00:18<00:00,  2.15it/s]\u001b[A\n",
      "100%|██████████| 35/35 [00:18<00:00,  2.47it/s]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/35 [00:02<01:09,  2.06s/it]\u001b[A\n",
      "  6%|▌         | 2/35 [00:03<01:03,  1.92s/it]\u001b[A\n",
      "  9%|▊         | 3/35 [00:05<01:01,  1.93s/it]\u001b[A\n",
      " 11%|█▏        | 4/35 [00:06<00:50,  1.63s/it]\u001b[A\n",
      " 14%|█▍        | 5/35 [00:08<00:55,  1.84s/it]\u001b[A\n",
      " 17%|█▋        | 6/35 [00:10<00:49,  1.71s/it]\u001b[A\n",
      " 20%|██        | 7/35 [00:11<00:47,  1.68s/it]\u001b[A\n",
      " 23%|██▎       | 8/35 [00:13<00:47,  1.78s/it]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:16<00:50,  1.93s/it]\u001b[A\n",
      " 29%|██▊       | 10/35 [00:17<00:44,  1.77s/it]\u001b[A\n",
      " 31%|███▏      | 11/35 [00:18<00:38,  1.59s/it]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:20<00:36,  1.60s/it]\u001b[A\n",
      " 37%|███▋      | 13/35 [00:21<00:33,  1.53s/it]\u001b[A\n",
      " 40%|████      | 14/35 [00:23<00:36,  1.75s/it]\u001b[A\n",
      " 43%|████▎     | 15/35 [00:27<00:46,  2.33s/it]\u001b[A\n",
      " 46%|████▌     | 16/35 [00:30<00:46,  2.43s/it]\u001b[A\n",
      " 49%|████▊     | 17/35 [00:33<00:46,  2.56s/it]\u001b[A\n",
      " 51%|█████▏    | 18/35 [00:35<00:44,  2.62s/it]\u001b[A\n",
      " 54%|█████▍    | 19/35 [00:37<00:35,  2.24s/it]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:38<00:30,  2.05s/it]\u001b[A\n",
      " 60%|██████    | 21/35 [00:40<00:26,  1.88s/it]\u001b[A\n",
      " 63%|██████▎   | 22/35 [00:43<00:27,  2.11s/it]\u001b[A\n",
      " 66%|██████▌   | 23/35 [00:44<00:24,  2.03s/it]\u001b[A\n",
      " 69%|██████▊   | 24/35 [00:46<00:20,  1.89s/it]\u001b[A\n",
      " 71%|███████▏  | 25/35 [00:47<00:17,  1.75s/it]\u001b[A\n",
      " 74%|███████▍  | 26/35 [00:49<00:16,  1.79s/it]\u001b[A\n",
      " 77%|███████▋  | 27/35 [00:51<00:13,  1.74s/it]\u001b[A\n",
      " 80%|████████  | 28/35 [00:52<00:11,  1.63s/it]\u001b[A\n",
      " 83%|████████▎ | 29/35 [00:54<00:10,  1.70s/it]\u001b[A\n",
      " 86%|████████▌ | 30/35 [00:56<00:08,  1.70s/it]\u001b[A\n",
      " 89%|████████▊ | 31/35 [00:57<00:06,  1.60s/it]\u001b[A\n",
      " 91%|█████████▏| 32/35 [01:01<00:06,  2.14s/it]\u001b[A\n",
      " 94%|█████████▍| 33/35 [01:01<00:03,  1.77s/it]\u001b[A\n",
      " 97%|█████████▋| 34/35 [01:03<00:01,  1.75s/it]\u001b[A\n",
      "100%|██████████| 35/35 [01:05<00:00,  1.65s/it]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/35 [00:00<00:27,  1.25it/s]\u001b[A\n",
      "  6%|▌         | 2/35 [00:00<00:20,  1.64it/s]\u001b[A\n",
      "  9%|▊         | 3/35 [00:01<00:18,  1.70it/s]\u001b[A\n",
      " 11%|█▏        | 4/35 [00:01<00:15,  2.06it/s]\u001b[A\n",
      " 14%|█▍        | 5/35 [00:01<00:12,  2.43it/s]\u001b[A\n",
      " 20%|██        | 7/35 [00:02<00:09,  2.99it/s]\u001b[A\n",
      " 23%|██▎       | 8/35 [00:02<00:08,  3.11it/s]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:02<00:07,  3.37it/s]\u001b[A\n",
      " 29%|██▊       | 10/35 [00:02<00:06,  4.07it/s]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:03<00:04,  4.98it/s]\u001b[A\n",
      " 37%|███▋      | 13/35 [00:03<00:04,  5.32it/s]\u001b[A\n",
      " 40%|████      | 14/35 [00:03<00:05,  3.59it/s]\u001b[A\n",
      " 43%|████▎     | 15/35 [00:06<00:18,  1.05it/s]\u001b[A\n",
      " 46%|████▌     | 16/35 [00:06<00:15,  1.21it/s]\u001b[A\n",
      " 49%|████▊     | 17/35 [00:09<00:22,  1.25s/it]\u001b[A\n",
      " 51%|█████▏    | 18/35 [00:09<00:16,  1.06it/s]\u001b[A\n",
      " 54%|█████▍    | 19/35 [00:09<00:11,  1.36it/s]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:09<00:09,  1.64it/s]\u001b[A\n",
      " 60%|██████    | 21/35 [00:10<00:07,  1.99it/s]\u001b[A\n",
      " 63%|██████▎   | 22/35 [00:10<00:05,  2.17it/s]\u001b[A\n",
      " 66%|██████▌   | 23/35 [00:10<00:05,  2.16it/s]\u001b[A\n",
      " 69%|██████▊   | 24/35 [00:11<00:04,  2.38it/s]\u001b[A\n",
      " 71%|███████▏  | 25/35 [00:11<00:03,  2.84it/s]\u001b[A\n",
      " 74%|███████▍  | 26/35 [00:11<00:03,  2.55it/s]\u001b[A\n",
      " 77%|███████▋  | 27/35 [00:12<00:02,  2.84it/s]\u001b[A\n",
      " 80%|████████  | 28/35 [00:12<00:02,  3.25it/s]\u001b[A\n",
      " 83%|████████▎ | 29/35 [00:13<00:02,  2.18it/s]\u001b[A\n",
      " 86%|████████▌ | 30/35 [00:13<00:02,  2.28it/s]\u001b[A\n",
      " 89%|████████▊ | 31/35 [00:13<00:01,  2.78it/s]\u001b[A\n",
      " 91%|█████████▏| 32/35 [00:16<00:02,  1.01it/s]\u001b[A\n",
      " 94%|█████████▍| 33/35 [00:16<00:01,  1.32it/s]\u001b[A\n",
      "100%|██████████| 35/35 [00:16<00:00,  1.71it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "new_train_d = fill_missing_for_another(df_after_,df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing num of PM25:  35\n",
      "Missing num of PM10:  2310\n",
      "Missing num of O3:  35\n"
     ]
    }
   ],
   "source": [
    "pp = [\"PM25\",\"PM10\",\"O3\"]\n",
    "for p in pp:\n",
    "    m_n = len(new_train_d.loc[new_train_d[p].isnull()])\n",
    "    print('Missing num of %s: '%p, m_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_d.to_csv(AFTER_FILE_FOLDER % 'train_data_after_first_filling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153160"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
